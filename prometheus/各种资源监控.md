# 第x章 容器监控

学习Docker的时候我们已经知道收集docker容器使用的是cAdvisor,而k8s的kubelet已经内置了cAdvisor。所以我们只需要访问即可，这里我们可以使用访问kubelet的暴露的地址访问cAdvisor数据。地址为：nodeip/metrics/cadvisor

配置文件：

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: prom
data:
  prometheus.yml: |                             
    global:
      scrape_interval: 15s
      scrape_timeout: 15s
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
    
    - job_name: 'coredns'
      static_configs:
      - targets: ['10.2.0.2:9153', '10.2.1.61:9153']

    - job_name: 'mysql'
      static_configs:
      - targets: ['mysql-svc.default:9104']

    - job_name: 'nodes'
      kubernetes_sd_configs:                #k8s自动服务发现
      - role: node                                  #自动发现类型为node
      relabel_configs:
      - action: replace     
        source_labels: ['__address__']      #需要修改的源标签 
        regex: '(.*):10250'                         #正则表达式(10.0.0.10):10250
        replacement: '${1}:9100'            #替换后的内容10.0.0.10:9100
        target_label: __address__           #将替换后的内容覆盖原来的标签
      - action: labelmap                            #将正则表达式与所有标签名称匹配
        regex: __meta_kubernetes_node_label_(.+)    #提取符合正则匹配的标签，然后天交到Label里

    - job_name: 'kubelet'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)

    - job_name: 'cadvisor'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__metrics_path__]
        regex: (.*)
        replacement: /metrics/cadvisor
        target_label: __metrics_path__
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
        
    - job_name: 'kubernetes-cadvisor'
      kubernetes_sd_configs:
        - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
          replacement: $1
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          replacement: /metrics/cadvisor
          target_label: __metrics_path__
```

应用配置:

```
[root@node1 prom]# kubectl apply -f prom-cm.yml 
configmap/prometheus-config configured

[root@node1 prom]# curl -X POST "http://10.2.2.86:9090/-/reload"
```

查看结果：

![](https://cdn.nlark.com/yuque/0/2024/png/830385/1726449160098-e3ac98dd-23f9-49ef-b0b8-b760176518c1.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_53%2Ctext_6Lev6aOe5a2m5Z-O%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

关于查询的数据可以查看官网的说明：

https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md

# 第x章 API Server监控

API Server是k8s的核心组件，对于API Server的监控我们可以直接通过k8s的Service来获取：

```
[root@node1 prom]# kubectl get svc
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.1.0.1     <none>        443/TCP   10d
```

修改配置:

```
- job_name: 'apiservers'
      kubernetes_sd_configs:
      - role: endpoints
```

应用配置：

```
kubectl apply -f prom-cm.yml 
curl -X POST "http://10.2.2.86:9090/-/reload"
```

查看结果：

![](https://cdn.nlark.com/yuque/0/2024/png/830385/1726449160403-c6ccbafd-0445-44e8-8fd4-b7d55ae00510.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_72%2Ctext_6Lev6aOe5a2m5Z-O%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

这时我们发现promtheus把所有的endpoint都找出来了，那么哪个才是我们需要的呢？通过查看API Server的svc可以发现API Server的通讯端口是6443，所以6443端口的服务才是我们需要的。

```
[root@node1 prom]# kubectl describe svc kubernetes 
Name:              kubernetes
Namespace:         default
Labels:            component=apiserver
                   provider=kubernetes
Annotations:       <none>
Selector:          <none>
Type:              ClusterIP
IP:                10.1.0.1
Port:              https  443/TCP
TargetPort:        6443/TCP
Endpoints:         10.0.0.11:6443
Session Affinity:  None
Events:            <none>
```

要想保留我们发现的的API Server，那么就需要查看他都有什么标签，然后将拥有这些标签的服务保留下来。

![](https://cdn.nlark.com/yuque/0/2024/png/830385/1726449160450-2fdf7a75-48c6-450f-bfbb-ed6518fefb12.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_46%2Ctext_6Lev6aOe5a2m5Z-O%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

我们需要匹配的条件是标签名为__meta_kubernetes_service_label_component 的值为"apiserver"的服务。

因为这个端口是https协议的，所以我们还需要带上认证的证书。

修改配置文件：

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: prom
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 15s
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
    
    - job_name: 'coredns'
      static_configs:
      - targets: ['10.2.0.16:9153','10.2.0.17:9153']
    
    - job_name: 'mysql'
      static_configs:
      - targets: ['mysql-svc:9104']
   
    - job_name: 'nodes'
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - source_labels: ['__address__']
        regex: '(.*):10250'
        replacement: '${1}:9100'
        target_label: __address__
        action: replace
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
     
    - job_name: 'kubelet'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)   

    - job_name: 'cadvisor'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)   
        replacement: $1
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.*)
        replacement: /metrics/cadvisor
        target_label: __metrics_path__
     
    - job_name: 'apiservers'
      kubernetes_sd_configs:
      - role: endpoints 
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_component]
        action: keep
        regex: apiserver
```

应用修改：

```
kubectl apply -f prom-cm.yml 
curl -X POST "http://10.2.2.86:9090/-/reload"
```

查看结果：

![](https://cdn.nlark.com/yuque/0/2024/png/830385/1726449160454-eb0d1e86-78b7-4d9e-af9a-535ae89b3f42.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_55%2Ctext_6Lev6aOe5a2m5Z-O%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10)

# 第x章 Pod监控

我们这里采集到的Pod监控也是使用自动发现Endpoints。只不过这里需要做一些匹配的处理.

配置如下：

```
- job_name: 'pods'
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
```

生效配置：

```
kubectl apply -f prom-cm.yml 
curl -X POST "http://10.2.2.86:9090/-/reload"
```



匹配参数解释：

```
__meta_kubernetes_service_annotation_prometheus_io_scrape 为 true
__address__的端口和__meta_kubernetes_service_annotation_prometheus_io_port 的端口一样
```

自动发现原理：我们创建svc的时候添加了prometheus和metrics端口的注解，这样就能被prometheus自动发现到

```
[root@node1 prom]# kubectl -n kube-system get svc kube-dns -o yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/port: "9153"
    prometheus.io/scrape: "true"
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: KubeDNS
```

对应promethues自动发现里的数据：以后发布的应用，我们只需要添加这两条注解就可以被自动发现了，现在我们可以来修改下刚才创建的mysql配置，添加相关注解就可以自动被发现了。

```
---
kind: Service
apiVersion: v1
metadata:
  name: mysql-svc
  namespace: prom
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9104"
spec:
  selector:
    app: mysql
  ports:
  - name: mysql
    port: 3306
    targetPort: 3306
  - name: mysql-prom
    port: 9104
    targetPort: 9104
```

查看prometheus可以发现mysql的pod已经自动被发现了

们配置的静态mysql了，同理，我们刚才静态配置的coredns也可以删掉了，同样使用自动发现来处理,配置如下：

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: prom
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 15s
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
    
    #- job_name: 'coredns'
    #  static_configs:
    #  - targets: ['10.2.0.16:9153','10.2.0.17:9153']
    
    
    #- job_name: 'mysql'
    #  static_configs:
    #  - targets: ['mysql-svc:9104']
    
    - job_name: 'nodes'
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - source_labels: ['__address__']
        regex: '(.*):10250'
        replacement: '${1}:9100'
        target_label: __address__
        action: replace
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
     
    - job_name: 'kubelet'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)   

    - job_name: 'cadvisor'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)   
        replacement: $1
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.*)
        replacement: /metrics/cadvisor
        target_label: __metrics_path__
     
    - job_name: 'apiservers'
      kubernetes_sd_configs:
      - role: endpoints 
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_component]
        action: keep
        regex: apiserver

    - job_name: 'pods'
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name

    - job_name: 'coredns'
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
      - source_labels: [__meta_kubernetes_endpoints_name]
        action: keep
        regex: kube-dns
```

应用配置：

```
kubectl apply -f prom-cm.yml 
curl -X POST "http://10.2.2.86:9090/-/reload"
```

