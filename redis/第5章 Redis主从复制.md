# 第5章 Redis主从复制

### 1.Redis主从复制介绍

我们已经介绍过了Redis的持久化功能，虽然通过持久化可以确保数据最大限度的不丢失，但是假如服务器因为系统问题导致了宕机，如果我们只有一台Redis，那么即使做了持久化也没有办法继续提供访问了。所以为了解决数据单点问题，Redis提供了多种高可用的方案，包括：主从复制，哨兵模式和集群模式。

Redis的主从复制部署起来非常简单，但是比主从复制更高级的哨兵模式和集群模式都要依赖于主从复制，所以了解主从复制的流程对于理解后面的集群实验十分有帮助。

### 2.Redis主从复制搭建部署

#### 1）节点规划

这里我们以单机多实例的方式部署第2个Redis节点来作为从库.IP和端口如下：

主节点: 10.0.0.51:6379

从节点: 10.0.0.51:6380

#### 2）创建第二个redis实例

第1步：创建目录

```bash
[root@db-51 ~]# mkdir -p /opt/redis_6380/{conf,logs,pid} 
[root@db-51 ~]# mkdir -p /data/redis_6380
```

第2步：创建配置文件

```bash
[root@db-51 ~]# cat /opt/redis_6380/conf/redis.conf
daemonize yes
bind 127.0.0.1 10.0.0.51
port 6380
pidfile /opt/redis_6380/pid/redis.pid
logfile /opt/redis_6380/logs/redis.log
dir /data/redis_6380
dbfilename redis.rdb
```

#### 3）启动第二个实例

启动命令

```bash
[root@db-51 ~]# redis-server /opt/redis_6380/conf/redis.conf
```

检查命令

```bash
[root@db-51 ~]# netstat -lntup|grep redis
tcp        0      0 127.0.0.1:6379          0.0.0.0:*               LISTEN      3040/redis-server 1 
tcp        0      0 10.0.0.51:6379          0.0.0.0:*               LISTEN      3040/redis-server 1 
tcp        0      0 127.0.0.1:6380          0.0.0.0:*               LISTEN      3338/redis-server 1 
tcp        0      0 10.0.0.51:6380          0.0.0.0:*               LISTEN      3338/redis-server 1
```

#### 4）配置主从关系

配置复制的命令非常简单，只需要一条命令即可：

```bash
slaveof {masterHost} {masterPort}    #<==slaveof 主库的IP 主库的端口
```

操作命令：

```bash
[root@db-51 ~]# redis-cli -p 6380    #<==指定登陆的节点端口号
127.0.0.1:6380> SLAVEOF 10.0.0.51 6379
OK
```

注意，此时我们只是临时的生效了主从复制关系，当我们重启之后复制关系就会断开，那么如何让主从复制关系一直建立呢？很简单，我们只需要把复制命令写入配置文件即可，这里我们也可以使用config rewrite命令来将命令自动写入配置文件。

```bash
127.0.0.1:6380> CONFIG REWRITE       #<==将当前配置写入配置文件
OK
```

此时我们再去查看一下配置文件就会发现新增了主从复制的参数。

```bash
[root@db-51 ~]# cat /opt/redis_6380/conf/redis.conf 
daemonize yes
bind 10.0.0.51 127.0.0.1
port 6380
pidfile "/opt/redis/pid/redis.pid"
logfile "/opt/redis/logs/redis.log"
dir "/data/redis"
dbfilename "redis.rdb"
# Generated by CONFIG REWRITE        #<==这是Redis自动添加的说明
replicaof 10.0.0.51 6379             #<==这是我们命令行输入的主从复制命令
```

#### 5）写入命令测试

主从复制虽然配置好了，但是我们还没有进行写入命令测试，下面我就在主库上写入测试的数据，然后在从库上验证是否可以正常同步并查看。

主节点操作命令：

```bash
[root@db-51 ~]# redis-cli -p 6379    #<==登陆6379端口
127.0.0.1:6379> set db-51 db-51      #<==写入一个键值对
OK
127.0.0.1:6379> get db-51            #<==查看刚才写入的键值对
"db-51"
```

从节点操作命令：

```bash
[root@db-51 ~]# redis-cli -p 6380    #<==登陆6380端口
127.0.0.1:6380> get db-51            #<==可以查看主库创建的数据，证明同步成功
"db-51"
```

我们发现从库确实可以从主库上同步数据，那么从库可不可以写入数据呢？我们来测试一下吧。

```bash
[root@db-51 ~]# redis-cli -p 6380    #<==登陆6380端口
127.0.0.1:6380> set db-52 db-52      #<==尝试写入命令
(error) READONLY You can't write against a read only replica.  #<==发现报错了，提示从库是只读的
```

通过上面的实验我们可以得出以下结论：

1.从库可以正常同步主库的数据。

2.从库只读不可写。

### 3.断开复制关系

我们已经建立好了主从复制复制关系，但是当主节点意外故障或者说我们想主动断开从库与主库的连接呢？

其实slaveof命令除了可以建立复制关系，也可以用来断开复制关系。命令参数如下：

```bash
slaveof no one       #<==主动断开复制关系，从节点升级为主节点
```

下面我们通过实验开验证一下断开复制命令：

第1步：主库写入数据

```bash
[root@db-51 ~]# redis-cli -p 6379
127.0.0.1:6379> set k1 v1
OK
127.0.0.1:6379> get k1
"v1"
```

第二步：从库验证数据

```bash
[root@db-51 ~]# redis-cli -p 6380
127.0.0.1:6380> SLAVEOF 10.0.0.51 6379
OK
127.0.0.1:6380> get k1
"v1"
```

第三步：从库断开复制关系

```bash
127.0.0.1:6380> SLAVEOF no one       #<==从库执行断开复制命令
OK
127.0.0.1:6380> get k1
"v1"
```

第四步：主库继续写入数据验证从库是否仍会同步

```bash
[root@db-51 ~]# redis-cli -p 6379    
127.0.0.1:6379> set k2 v2
OK
127.0.0.1:6379> get k2
"v2"
```

第五步：登陆从库验证

```bash
[root@db-51 ~]# redis-cli -p 6380
127.0.0.1:6380> keys *
1) "k1"
```

我们可以看到，从库确实已经不会从主库继续复制数据了，查看数据会发现已经同步过的数据依然还会保留着。

### 4.日志分析主从复制流程

通过分析日志可以让我们更清晰的理解主从复制的流程，我们将主库和从库的日志过按照时间线的顺序简化后排列如下：

1.从库发送复制请求：

```bash
19:54:03.778 * Connecting to MASTER 10.0.0.51:6379
19:54:03.778 * MASTER <-> REPLICA sync started
19:54:03.778 * Non blocking connect for SYNC fired the event.
```

2.主库接收到从库的复制请求后开始持久化数据：

```bash
19:54:03.779 * Replica 127.0.0.1:6380 asks for synchronization
19:54:03.779 * Starting BGSAVE for SYNC with target: disk
19:54:03.778 * Connecting to MASTER 10.0.0.51:6379
19:54:03.778 * MASTER <-> REPLICA sync started
19:54:03.778 * Non blocking connect for SYNC fired the event.
```

3.主库将持久化后的RDB文件发给从库：

```bash
19:54:03.784 * DB saved on disk
19:54:03.785 * RDB: 4 MB of memory used by copy-on-write
19:54:03.880 * Background saving terminated with success
19:54:03.880 * Synchronization with replica 127.0.0.1:6380 succeeded
```

4.从库接收到主库发来的RDB文件后做了2件事：

1）清空自己的旧数据

```bash
19:54:03.880 * MASTER <-> REPLICA sync: receiving 208 bytes from master
19:54:03.880 * MASTER <-> REPLICA sync: Flushing old data
```

2）载入主库的发送过来的数据

```bash
19:54:03.881 * MASTER <-> REPLICA sync: Loading DB in memory
19:54:03.881 * MASTER <-> REPLICA sync: Finished with success
```

5.复制关系建立成功，后续主库的命令都会被同步到从库上：

```bash
2020 19:54:03.880 * Background saving terminated with success
2020 19:54:03.880 * Synchronization with replica 127.0.0.1:6380 succeeded
```

### 5.主从复制需要注意的问题

在工作中使用Redis主从复制我们需要注意以下几点问题

1.主库意外宕机后从库并不会主动切换，需要人工介入修复。

2.从库建立复制关系时会清空自己当前所有的数据，然后载入主库发送过来的数据。

3.从库只读不可写，不能分担主库写入压力。

4.从库断开复制关系后会保留自己的数据，只是无法再从主库上获取数据。

5.如果主库做了安全密码认证，那么从库也需要再配置文件里添加一个主库密码的参数

masterauth 主库密码

## 6.redis主从复制信息

```bash
role: 表明当前服务器的角色，这里是slave，即从节点。

master_host: 主节点的IP地址，这里是10.0.0.51。

master_port: 主节点的端口号，这里是6379。

master_link_status: 从节点与主节点的连接状态，up表示当前正常连接。

master_last_io_seconds_ago: 上一次从主节点接收数据的时间，单位是秒，这里是8秒前。

master_sync_in_progress: 是否有正在进行的同步操作，0表示没有同步正在进行。

slave_repl_offset: 从节点的复制偏移量，标识从节点复制数据的进度，这里是389046。

slave_priority: 从节点的优先级，用于故障转移决策。数值越小，优先级越高，这里是100。

slave_read_only: 从节点是否只读，1表示只读。

connected_slaves: 连接到当前从节点的其他从节点数量，这里是0。

master_replid: 主节点的复制ID，这是一个唯一标识符，用于追踪复制进程，这里是4a50f7c2ab74042671208a6390de746d76361dc7。

master_replid2: 第二个复制ID，用于在主节点故障恢复后保持复制连续性，这里显示为全0，表示当前未使用。

master_repl_offset: 主节点的复制偏移量，与从节点的slave_repl_offset应当相匹配，这里也是389046。

second_repl_offset: 第二个复制偏移量，通常用于故障恢复，这里是-1，表示未使用。

repl_backlog_active: 复制积压缓冲区是否激活，1表示激活。

repl_backlog_size: 复制积压缓冲区的大小，这里是1048576字节。

repl_backlog_first_byte_offset: 复制积压缓冲区中的第一个字节的偏移量，这里是388613。

repl_backlog_histlen: 复制积压缓冲区中数据的长度，这里是434字节。
```